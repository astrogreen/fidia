"id";"title";"topic_id";"slug";"content";"created";"updated";"edit_group_id";"hidden";"order"
35;"How do I download catalogues?";6;"downloading-data-how-do-i-download-catalogues";"<p>Content</p>";"2016-09-01 09:34:24.849004+08";"2016-09-01 09:34:33.770257+08";;FALSE;0
36;"How do I create a sample?";6;"downloading-data-how-do-i-create-a-sample";"Content";"2016-09-01 09:34:50.887645+08";"2016-09-01 09:34:50.887694+08";;FALSE;0
34;"How do I download data products?";6;"downloading-data-how-do-i-download-data-products";"<h2>What can I download?</h2> <p>Data-types at the AAODC can be broadly split into (astronomical) objects and samples of astronomical objects.</p> <h3>Objects</h3> <p>Individual objects are single astronomical entities (stars, galaxies or groups of galaxies), all of which contain a variety of properties appropriate to their type. A star, for example, may have a value for surface gravity (if it has been calculated by a survey team), whereas a galaxy would not.</p> <p>You can immediately download individual data products for an astronomical object from the Data Browser by clicking on the <a class=""btn btn-default btn-xs""> <span class=""fa-custom-stack""><span class=""fa-custom-filetype"">fits</span></span>fits</a> (see the documentation for more details).</p> <h3>Samples</h3> <p>Samples are constructed by making a query against the AAODC database, using either the Query Builder, or pure SQL.</p>";"2016-09-01 09:33:57.049779+08";"2016-09-01 15:52:03.85135+08";;FALSE;0
32;"How do I update my account details?";5;"my-account-how-do-i-update-my-account-details";"<p>If you wish to update your profile information, first&nbsp;visit the <a href=""http://datacentral.aao.gov.au/asvo/sign-in/"">Sign In</a> page and sign in. Once you are authenticated, you may access your profile in the top-right hand corner of the page.&nbsp;</p> <p>Select the&nbsp;<code>update details&nbsp;</code>panel,&nbsp;you can update your first name, last name, and email address.</p>";"2016-08-31 14:54:06.167487+08";"2016-10-07 09:28:39.14408+08";;FALSE;0
33;"How do I change my account password?";5;"my-account-how-do-i-change-my-account-password";"<p>If you wish to change&nbsp;your password, first&nbsp;visit the <a href=""http://datacentral.aao.gov.au/asvo/sign-in/"">Sign In</a> page and sign in. Once you are authenticated, you may access your profile in the top-right hand corner of the page.&nbsp;</p> <p>Select the&nbsp;<code>update details</code> panel, and click the <a href=""http://datacentral.aao.gov.au/asvo/password-change/"">Change Password</a> link. You will be asked for your old password, as well as your new password.&nbsp;</p>";"2016-08-31 14:54:28.898321+08";"2016-10-07 09:29:26.109588+08";;FALSE;0
31;"How do I create an account?";5;"my-account-how-do-i-create-an-account";"<p>To create an account on&nbsp;AAODC, please <a href=""http://datacentral.aao.gov.au/asvo/register/"">register</a>&nbsp;using an email address and password.</p> <p><a href=""http://datacentral.aao.gov.au/asvo/docs/articles/my-account-why-should-i-create-an-account/"">Why should I create an account?</a></p>";"2016-08-31 14:42:27.313584+08";"2016-10-07 09:34:17.203597+08";;FALSE;0
29;"How do I delete my account?";5;"my-account-how-do-i-delete-my-account";"<p>If you wish to delete your account, first&nbsp;visit the <a href=""http://datacentral.aao.gov.au/asvo/sign-in/"">Sign In</a> page and sign in. Once you are authenticated, you may access your profile in the top-right hand corner of the page.&nbsp;</p> <p>Select the&nbsp;<code>delete account</code>&nbsp;panel, and click&nbsp;Delete.&nbsp;</p> <p><em><span class=""text-error"">WARNING</span> Deleting your account is irreversible. Please be sure you wish to proceed.</em></p>";"2016-08-31 14:41:31.099152+08";"2016-10-07 09:35:13.908521+08";;FALSE;0
45;"How do I report an issue?";26;"support-how-do-i-report-an-issue";"<p>If you spot a problem with the web interface, or an issue with data fidelity please&nbsp;submit a <a href=""http://datacentral.aao.gov.au/asvo/support/bug-report/"">bug report</a>.&nbsp;test</p>";"2016-09-01 13:43:00.884099+08";"2016-11-23 12:20:43.678401+08";;FALSE;0
30;"Why should I create an account?";5;"my-account-why-should-i-create-an-account";"<p>Registration is not required to view the publically available data products hosted at ADC, unregistered users&nbsp;can access the Single Object Viewer, Schema Browser, and make use of the Download functionality to download collections of individual data products.</p> <p>However, there are some things you won't be able to access without registering. These include querying the data (using the Query Builder) to create unique samples&nbsp;and bulk downloading of data products for objects in those samples. Each query is associated to a particular user, and recorded against your Query History for you to revisit later.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p>";"2016-08-31 14:42:11.694998+08";"2016-11-21 15:02:49.140508+08";;FALSE;0
39;"Examples";2;"query-examples";"<h2>Query Builder</h2> <h3>1. Return all galaxies in a pair, with redshift (0.1 &lt; z &lt; 0.3) and quality flag cut.</h3> <div class=""row""> <div class=""col-sm-6""> <table class=""table table-bordered ""> <thead> <tr> <th>DMU</th> <th>Catalogue</th> <th>Parameter</th> <th>Info</th> </tr> </thead> <tbody> <tr> <th scope=""row"">Groupfindingv05</th> <td>G3CGalsInPair</td> <td>Gal1CATAID, Gal2CATAID</td> <td>G3CGalsInPair is a catalogue of galaxies that live in pairs (thus gal1-gal2 and gal2-gal1 combinations are both listed), so here we need only match to Gal1CATAID.</td> </tr> <tr> <th scope=""row"">StellarMassesv08</th> <td>StellarMasses</td> <td>CATAID, Z, nQ</td> <td>All CATAID matched to Gal1CATAID, where 0.1 &lt; Z &lt; 0.3, nQ &gt; 2</td> </tr> </tbody> </table> </div> </div> <p>&nbsp;</p> <h2>SQL</h2> <p>coming soon.</p> <p>&nbsp;</p>";"2016-09-01 09:52:47.209772+08";"2016-09-01 09:52:47.209804+08";;TRUE;0
41;"How do I download data products for the objects in a query result?";2;"query-how-do-i-download-data-products-for-the-objects-in-a-query-result";"<p>Content</p>";"2016-09-01 10:08:59.563316+08";"2016-09-22 18:07:45.135149+08";;TRUE;0
8;"Data Model";4;"data-central-data-model";"<p><span>Here at ADC&nbsp;we've adopted an astronomical object-orientated data model. Data are organised into <code>samples</code> containing <code>astronomical objects</code>, such as stars and galaxies, with <code>data members</code> such as spectra, magnitudes and velocities. By presenting the properties and measurements of objects in this way, we simplify analysis and visualisation by providing a uniform representation of an astrophysical object's characteristics. </span><span>This data model allows us to serve data at restful endpoints, providing an API to those wishing to access data without using a web browser.&nbsp;Within the Single Object Viewer, data are organised hierarchically, according to the following structure:</span></p> <dl class=""""> <dt> <p><strong>survey/</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Available survey objects, products, schema browser etc.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/"">sov/sami/</a></p> </dd> <dt> <p><strong>survey/galaxy</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Available data for the object 'galaxy'.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/"">sov/sami/24433/</a></p> </dd> <dt> <p><strong>survey/galaxy/trait/</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Displays an on-the-fly rendering of the property (if sensible). Download in a variety of formats [fits, json, csv].</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729"">sov/sami/24433/line_emission_map-OII3729</a></p> </dd> <dt> <p><strong>survey/galaxy/trait/property</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Displays a list of the properties&nbsp;belonging to the trait.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729/value/"">sov/sami/24433/line_emission_map-OII3729/value/</a></p> </dd> <dt> <p>&nbsp;</p> </dt> <dd></dd> <dt> <p>&nbsp;</p> </dt> <dd></dd> </dl> <p>&nbsp;<span>This has the added advantage of data being self discoverable. </span><span style=""color: #333333; font-family: Roboto, 'Helvetica Neue Light', 'Helvetica Neue', Helvetica, Arial, 'Lucida Grande', sans-serif; font-size: 16px; line-height: 25.6px;""></span></p> <p>You can read more about our middleware python package, FIDIA&nbsp;<a style=""box-sizing: border-box; color: #4078c0; text-decoration: none; background-color: transparent;"" href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-a-format-independent-data-interface-for-astronomy-fidia/"">here</a>.</p> <h3 style=""box-sizing: border-box; font-family: Roboto, 'Helvetica Neue Light', 'Helvetica Neue', Helvetica, Arial, 'Lucida Grande', sans-serif; font-weight: 400; line-height: 40px; color: #232829; margin-top: 20px; margin-bottom: 10px; font-size: 20px;"">Why Object-Orientated?</h3> <p>Our middleware Python package, FIDIA, interacts with data for astronomical objects in a consistent and intuitive manner, regardless of the source or format of the data. Considerable past work has focused on standardised formats and protocols for working with data. However, these tools are structured around images and tables, not stars and galaxies. We take such work a step further by defining an interface to data on disk, on the web, in a database, etc. that has a vocabulary (based in part on existing IVOA UCDs) for the physical properties of astronomical objects. In our package, the primary objects are astronomical objects, such as stars and galaxies, with data members such as spectra, magnitudes and velocities. By presenting the properties and measurements of objects in this way, we simplify analysis and visualisation by providing a uniform representation of an astrophysical object's characteristics.</p> <p>The package accepts that data will always be available in a wide variety of formats and places, and therefore it provides a formulaic way to connect to and import from new data sources with ease. Cross matching is done between data sources as needed. Throughout, FIDIA has been designed to deliver the most likely result in the face of ambiguity, such as multiple versions of data or multiple potential cross-matches, but allow for arbitrary, repeatable reconfiguration. Our aim with FIDIA is to provide a consistent and intiutive experience for all ADC&nbsp;users, regardless of astronomical knowledge, and to provide a scalable and consistent&nbsp;data model for connecting new data tools to our interface.</p>";"2016-08-26 17:50:57.926894+08";"2016-11-24 11:17:05.135374+08";;FALSE;0
11;"A Format Independent Data Interface for Astronomy: FIDIA";4;"data-central-a-format-independent-data-interface-for-astronomy-fidia";"<p class=""lead"">...because I don&rsquo;t care what format the spectra is in!!!</p> <p>At ADC we use a custom-build middleware package to organise and access astronomical data. FIDIA seeks to free the astronomer to think about stars and galaxies and their spectra, magnitudes, velocities and other properties by combining a standardised, high-level data model with community developed interfaces to many common data sources. Analysis code written using FIDIA is&nbsp;highly portable, making it easier to apply existing analysis methods to new data, or bring existing data into new analysis.</p> <h2>Why &ldquo;Format Independent&rdquo;?</h2> <p>While the computer literate among us discuss and debate endlessly the advantages and disadvantages of various data formats, most astronomers just want to get on with doing science. They only care about the format of data if they can&rsquo;t open and interact with their own and communal data seamlessly in their analysis tool of choice. A uniform Data Program Interface (or Data API) for astronomy simplifies not only the options for the astronomer to interact with data from various sources and in various formats, but also offer the possibility for developers to support multiple formats and sources with no additional development cost.&nbsp;</p> <h2>Context</h2> <p>More and more, astronomy is becoming a data driven rather than observation driven science. Astronomers now care as much about bringing together diverse existing data sets and applying new analysis as about collecting new data and applying existing analysis methods. Both of these depend on interacting with data in a variety of formats and places (FITS, HDF, cloud based, database, files, etc.) The IVOA has already developed a comprehensive set of standards covering data storage (VOTables), data communication (TAP, SAMP), and data typing (Universal Content Descriptors) to help make interaction with data as seamless as possible. FIDIA can take advantage of that infrastructure where available, but can work around its absence when necessary to provide a consistent experience for the astronomer for all data sets.</p> <h2>What is FIDIA?</h2> <p>FIDIA is a Python package for interacting with data for astronomical objects in a consistent and intuitive manner, regardless of the source or format of the data. It also provides a standardised, high level data model, organising data by astronomical object and physical meaning. The package accepts that data will always be available in a wide variety of formats and places, and therefore it provides a formulaic way to connect to and import from new data sources such as on the user&rsquo;s computer. The package takes care of mundane details such as memory management, local caching, unit tracking, etc. The reference package is written in Python, but implementations in other languages are possible.</p> <p>Following the success of astropy, FIDIA invites community contributions to reduce the need for astronomers to re-invent data import code or develop new data models. Plug-ins for data access can read both local and remote data, eliminating the need to download large remote data sets, and allowing code to be uploaded for &ldquo;bring code to the data&rdquo; style execution.</p> <p>&nbsp;</p>";"2016-08-31 08:40:36.531548+08";"2016-11-24 11:17:09.451663+08";;FALSE;1
22;"Future Milestones";4;"data-central-future-milestones";"<p><span>AAO Data central (the AAT Node of the ASVO)&nbsp;aims to provide IVOA-compliant access to all AAT and UKST data including legacy (2dFGRS, 6dFGS, WiggleZ, RAVE, GAMA), ongoing (SAMI, GALAH, OzDES, 2dFLenS) and future (TAIPAN, FunnelWeb) surveys.</span></p> <p><span>The AAT Node of the ASVO is the subject of a funding agreement between the Commonwealth Department of Industry, Innovation and Science (DoIIS) and Astronomy Australia Limited (AAL). AAL has coordinated with the Australian Astronomical Observatory (AAO), as the owners and operators of the AAT, to develop this ASVO Node. This is a 2 year project with completion expected by June 2017.</span></p> <p>&nbsp;</p> <p>&nbsp;</p>";"2016-08-31 13:49:29.427338+08";"2016-11-24 11:17:28.741163+08";;FALSE;6
44;"What's my storage limit?";5;"my-account-whats-my-storage-limit";"Content";"2016-09-01 11:58:38.508651+08";"2016-09-01 11:58:38.508704+08";;TRUE;0
50;"How can I view a survey's data products available for a particular star/galaxy/group?";27;"data-access-how-can-i-view-a-surveys-data-products-available-for-a-particular-stargalaxygroup";"<p>For users wanting to&nbsp;<span>browse the available data, data products, and meta-data provided by&nbsp;a particular survey, use the <a href=""http://datacentral.aao.gov.au/asvo/sov/"">Single Object Viewer</a> Tool. For help using the Single Object Viewer, check out all the&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/docs/articles/sov/"">Single Object Viewer Articles</a>.</span></p>";"2016-09-21 15:59:37.333581+08";"2016-11-18 14:23:43.161243+08";;FALSE;0
58;"Bulk Data Downloads";27;"data-access-bulk-data-downloads";"<p><span>All data can be downloaded directly from ADC using the</span><span>&nbsp;</span><a href=""http://rsync.samba.org/""><span>rsync</span></a><span> or </span><a href=""http://www.gnu.org/software/wget/"">wget</a><span> commands. The urls to use are the same as you would use in a web browser, but with the relevant download format appended i.e.,&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-HALPHA/?format=fits"">http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-HALPHA/?format=fits</a></span></p> <p><span>For a detailed description of the directory structure, see the <a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-data-model/"">Data Model</a>, and to check available file formats, check the <a href=""http://datacentral.aao.gov.au/asvo/data-access/schema/"">Schema Browser</a>.&nbsp;</span></p> <p>Note: the total SAMI data volume is &gt; 1TB, and GAMA &gt; 10TB. If you need a significant fraction of that data (&gt;50GB), please <a href=""http://datacentral.aao.gov.au/asvo/support/contact/"">contact us</a>&nbsp;to arrange a data transfer.&nbsp;</p> <h3>Data Products</h3> <p>Data products as derived by the survey teams are documented in the <a href=""http://datacentral.aao.gov.au/asvo/data-access/schema/"">Schema Browser</a>.&nbsp;These can be directly downloaded from the links in the <a href=""http://datacentral.aao.gov.au/asvo/sov/"">Single Object Viewer</a>, or via wget commands.</p> <p>For example, to download the&nbsp;[NII] (6583&Aring;) and&nbsp;[OII] (3729&Aring;)&nbsp;emission line flux&nbsp;maps for SAMI galaxy 24433:</p> <pre>wget \<br /><a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729/?format=fits"">http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729/?format=fits</a> \ <br /><a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-NII6583/?format=fits"">http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-NII6583/?format=fits</a> <br /><br /></pre> <p>or alternatively, use the links on the Available Data&nbsp;section in the Data Browser page for <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/"">SAMI 24433</a>.&nbsp;</p> <h3>Catalogs&nbsp;</h3> <p>Catalogs of parameters derived by survey teams can be directly downloaded from the&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/sov/"">Single Object Viewer</a>&nbsp;using the Multiple objects section in the Survey section (e.g, <a href=""http://datacentral.aao.gov.au/asvo/surveys/sami/"">SAMI</a>).&nbsp;</p> <p>&nbsp;</p>";"2016-10-06 18:57:32.563923+08";"2016-11-18 14:25:38.972789+08";;FALSE;0
57;"How do I use the Schema Browser?";3;"schema-browser-how-do-i-use-the-schema-browser";"<p><span>The Schema Browser contains detailed information about each type of data product and derived property as defined by the survey teams.&nbsp;</span></p> <p><span>The schema for each data product will typically contain:</span></p> <ol> <li>Documentation: a detailed description of the selected data.</li> <li>Properties: descriptions of the associated data properties.</li> <li>Downloadable Formats: a list of formats the data can be downloaded as.</li> <li>All Available Branches and Previous Versions: a comprehensive table of all the available branches and versions for this type of data. Use the branch and version description dropdown to at the top of the schema to switch between branches and versions.</li> </ol>";"2016-10-06 12:25:45.217658+08";"2016-11-21 12:53:05.110588+08";;FALSE;0
27;"What is the Schema Browser for?";3;"schema-browser-what-is-the-schema-browser-for";"<p><span>The Schema Browser reflects the&nbsp;tree-like organisational structure we've adopted here at ADC. Each survey is a collection of astronomical objects with a certain set of properties, and the schema displays data products and derived properties&nbsp;provided for a particular survey. E.g., </span><a href=""http://datacentral.aao.gov.au/asvo/schema-browser/sami/"">schema-browser/sami/</a><span>&nbsp;is the schema browser for the SAMI survey-team derived products and properties.&nbsp;</span></p> <p>While the <a href=""http://datacentral.aao.gov.au/asvo/sov/"">SOV</a> provides a portal to the data products and derived properties hosted at ADC (collectively known as traits), the <a href=""http://datacentral.aao.gov.au/asvo/data-access/schema/"">Schema Browser</a> provides a map of those data products and derived properties, providing&nbsp;extensive documentation&nbsp;for each&nbsp;trait type (including analysis, comments from the team etc).&nbsp;</p> <p>&nbsp;</p> <p>The Schema Browser also provides information relevant to accessing the data using the API (full documentation to be released in the coming weeks).&nbsp;</p> <p>&nbsp;</p>";"2016-08-31 14:39:41.327418+08";"2016-11-21 13:15:20.960903+08";;FALSE;0
40;"Data Release Process";20;"policies-data-release-process";"<p>In progress...</p>";"2016-09-01 09:55:46.294066+08";"2016-10-07 09:40:44.895773+08";;TRUE;0
51;"Which tool do I need? View use cases for the ADC tools.";27;"data-access-which-tool-do-i-need-view-use-cases-for-the-adc-tools";"<p><span>ADC survey&nbsp;data can be accessed in a multitude of ways, depending on your data needs. Please note that ADC is still in development, and this table may change.</span></p> <table class=""table table-striped table-bordered table-condensed""><colgroup> <col width=""40%"" /> <col width=""10%"" /> <col width=""10%"" /> <col width=""10%"" /> <col width=""10%"" /> <col width=""10%"" /> <col width=""10%"" /> </colgroup> <thead> <tr> <th>Use Case</th> <th><a>Data Browser</a></th> <th>Query Builder</th> <th>Data Explorer</th> <th>SQL</th> <th>SOV</th> <th>Position Search</th> </tr> </thead> <tbody> <tr> <td> <h4 class=""no-margin-top"">Survey Exploration</h4> <span>I want to browse the available data products, and meta-data for the astronomical objects (stars/galaxies/groups) in a particular survey. I want to download data products for a sample of objects from that survey.</span></td> <td><span class=""fa fa-check""></span>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Single Object</h4> <span>I know the object identifier according to the survey, e.g., GAMA object G65406. I want to explore and download the available data products for this object&nbsp;from <em>all</em> surveys.</span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Multiple objects from the same survey</h4> <span>I have a list of object IDs or positions of sources that reside in a survey (e.g., GAMA sources G65406, G106376). I wish to return survey-derived parameters for those sources (e.g., redshifts from GAMA catalogue SpecObjAll).</span></td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Create and return a sample from a survey</h4> <span>I want to create a sample of objects from a particular survey, filtering on some parameter(s) and return available rows of objects across several catalogues.&nbsp;</span></td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Download Data Products for a generatated sample.</h4> <span>I want to create a sample of objects from multiple surveys, filtering on some parameter(s) and select data products (from all surveys) to download for the resultant sample.</span></td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Multiple Objects from different surveys</h4> <span>I want to view the closest sources to an uploaded list of RA, DEC coordinates within some radius.</span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td><span class=""fa fa-check""></span>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">Cross match my sources with a survey</h4> <span>I want to upload a list of RA, DEC positions and cross match to all available survey objects, to within some radius.</span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> <td><span class=""fa fa-check""></span>&nbsp;</td> </tr> <tr> <td> <h4 class=""no-margin-top"">At Position</h4> <span>I want to view available data for some radius around RA, DEC coordinates.</span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> </tr> <tr> <td> <h4 class=""no-margin-top"">Look for available data</h4> <span>I want to view imaging (where available) and source positions for the AAT surveys.</span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;<span class=""fa fa-check""></span></td> <td>&nbsp;</td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> </tbody> </table>";"2016-09-21 16:05:10.753321+08";"2016-10-07 07:37:32.837124+08";;TRUE;0
23;"What is the Query Builder?";2;"query-what-is-the-query-builder";"<h3>Query Builder</h3> <p>To access most astronomy databases, a user must be proficient in the language of databases - SQL. However, we appreciate that some users may not want to learn another language in order to perform a relatively simple request, namely, <em>show me these rows from this table&nbsp;if they satisify some condition</em>.&nbsp;</p> <p>The Query Builder form allows you to construct complicated queries on the database with ease, without writing any code. It writes the SQL for you, reducing the time spent writing out code&nbsp;and navigating obtuse SQL errors, and more time accessing&nbsp;and exploring the data.&nbsp;</p> <p>Queries can be made on any querable-property in the ADC database (the schema alongside the Query Builder displays a list of properties that can be queried, and relevant meta data (descriptions etc).&nbsp;</p> <p>The&nbsp;<span>Query Builder</span> is sufficient for most use cases, however particularly complicated queries can still be submitted via the SQL form. In many cases, the Query Builder can be useful to write out the bulk of a long query, which can be copy-pasted into the SQL box for further user-editing.&nbsp;</p>";"2016-08-31 13:51:47.902639+08";"2016-09-22 18:56:19.522536+08";;TRUE;0
56;"How can I view the schema for a particular branch and version?";3;"schema-browser-how-can-i-view-the-schema-for-a-particular-branch-and-version";"<p>&nbsp;<span>The </span><a href=""http://datacentral.aao.gov.au/asvo/schema-browser/"">Schema Browser</a><span>&nbsp;will always show the default branch for a trait, but you can switch to view other branches&nbsp;using the </span><a class=""btn btn-default btn-xs dropdown-toggle"" type=""button"" data-toggle=""dropdown""><span class=""fa fa-code-fork""></span>&nbsp; Branches </a><span>dropdown in the top right hand corner of the page (e.g., see the&nbsp;</span><a href=""../../../schema-browser/sami/line_emission_map-OII3726/"">Line Emission Map &mdash; Oii3726 Schema</a><span>&nbsp;page).</span></p> <p>&nbsp;</p>";"2016-10-06 10:12:47.656208+08";"2016-11-21 15:02:22.372744+08";;FALSE;0
52;"How do I download data products for a sample of SAMI galaxies?";27;"data-access-how-do-i-download-data-products-for-a-sample-of-sami-galaxies";"<p>To define a sample of SAMI objects, use the table of catalog properties on the&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/surveys/sami/"">SAMI</a>&nbsp;survey page, which allows for filtering and searching. Once you have defined a sample, use the data products table to add or remove data products from your selection using the checkboxes. Warnings will appear if your selection contains more than 100 objects, as data volumes can be large (&gt;GB).&nbsp;</p> <p>Download your selected objects and data products (as .gz.tar) using the <span class=""fa fa-download""></span>&nbsp;Download button.</p> <p><span>To access data via a command line interface, read the documentation on <a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-access-bulk-data-downloads/"">bulk data downloads.</a></span></p>";"2016-09-21 16:58:08.506268+08";"2016-11-21 15:06:00.800316+08";;FALSE;0
24;"Reference: SQL Syntax";2;"query-reference-sql-syntax";"<h2>Select</h2> <p>Select the catalogues you wish to query via the <button class=""btn btn-default btn-xs btn-demo"" type=""button"">Catalogue </button> dropdown.Available columns for the selected catalogue will be shown in the <button class=""btn btn-default btn-xs btn-demo"" type=""button"">Columns </button> dropdown. If you are looking for a particular column, the search bar can help.Multiple catalogues can be added using the + Add Fields button. Currently, up to 5 catalogues can be queried simultaneously.</p> <h2>Join</h2> <p>If you have selected two or more catalogues to return results from, use the Join row to choose which columns from each are common fields. For example, you may want to return filtered results from both the catalogues <samp>g3cgal</samp> and <samp>specobj</samp>. In which case, you could join as: <button class=""btn btn-default btn-xs btn-demo"" type=""button"">G3CGAL.CATAID </button> <button class=""btn btn-default btn-xs btn-demo"" type=""button"">INNER </button> <button class=""btn btn-default btn-xs btn-demo"" type=""button"">SpecObj.CATAID </button> <br /><strong>If you wish to return columns from multiple catalogues, you must join the appropriate columns from each catalogue</strong>.<br />Supported join types are detailed below.</p> <table class=""table table-bordered""> <thead> <tr> <th>Join</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td><samp>INNER</samp></td> <td>Limited to the rows that exist in both tables. For example, in our join above, a <samp>CATAID</samp> that appears in both<samp>g3cgal</samp> and <samp>specobj</samp> catalogues would be returned, however if a <samp>CATAID</samp> appeared in only one of<samp>g3cgal</samp> and <samp>specobj</samp>, it would not be returned. If you are unsure which join type to select, <samp>INNER</samp> is usually the best option.</td> </tr> <tr> <td><samp>LEFT</samp></td> <td>All rows from the first (or left hand side) catalogue are preserved. Rows from the right hand catalogue will be returned <em>only</em> if they have a match in the left catalogue. Where there are values from the left catalogue and not the right, values will be set as <samp>NULL</samp>.</td> </tr> <tr> <td><samp>RIGHT</samp></td> <td>All rows from the second (or right hand side) catalogue are preserved. Rows from the left hand catalogue will be returned <em>only</em> if they have a match in the right catalogue. Where there are values from the right catalogue and not the left, values will be set as <samp>NULL</samp>.</td> </tr> <tr> <td><samp>OUTER</samp></td> <td>A full outer join returns all rows from both catalogues, regardless of whether there are any matches. As in the <samp>LEFT</samp> and <samp>RIGHT</samp> joins, empty values will be set at NULL.</td> </tr> </tbody> </table> <p>FilterSet the constraints that determine which rows of the above catalogues(s) will be returned by your query. Leaving this empty will simply return all rows.</p> <p>&nbsp;</p>";"2016-08-31 13:53:33.948357+08";"2016-08-31 13:56:58.03372+08";;TRUE;0
53;"A guide to using the Query Builder";2;"query-a-guide-to-using-the-query-builder";"<p>Follow the step by step instructions on how to use the Query Builder</p> <div class=""row""> <div class=""col-xs-12""> <div class=""sub-heading question""> <div class=""helper step step1"">Choose a catalogue, then select properties you wish to return. Add multiple catalogues and properties using the button.</div> </div> </div> </div> <div class=""row""> <div class=""col-xs-12""> <div class=""sub-heading question""> <div class=""helper step step2"">If you have selected multiple catalogues, you must join them using this panel.</div> </div> </div> </div> <div class=""row""> <div class=""col-xs-12""> <div class=""sub-heading question""> <div class=""helper step step3"">Choose criteria to filter the selection by.</div> </div> </div> </div> <div class=""row""> <div class=""col-xs-12""> <div class=""sub-heading question""> <div class=""helper step step4"">Any warnings will show here. Once you've fixed them, view the generated SQL. (Optional) Copy-paste this into the SQL box below to edit your query.</div> </div> </div> </div> <div class=""row""> <div class=""col-xs-12""> <div class=""sub-heading question""> <div class=""helper step step5"">Check all fields are populated, then submit your query!</div> </div> </div> </div>";"2016-09-22 18:08:09.431477+08";"2016-09-22 18:18:47.77206+08";;TRUE;0
28;"I lost my password. How can I reset it?";5;"my-account-i-lost-my-password-how-can-i-reset-it";"<p>If you have lost your password, please visit the <a href=""http://datacentral.aao.gov.au/asvo/sign-in/"">Sign In</a> page and click <strong>Reset.</strong> You will be asked to enter the email address that you signed up with. We will email you a link to reset your password.</p> <p>If you're not sure of the email address you signed up with, you will need to <a href=""http://datacentral.aao.gov.au/asvo/register/"">Register</a> for a new account.</p>";"2016-08-31 14:41:17.454846+08";"2016-11-21 15:03:26.589939+08";;FALSE;0
42;"What is a Data Release?";4;"data-central-what-is-a-data-release";"<p>A data release is marked by the <span class=""fa fa-map-marker""></span>&nbsp;symbol, and represents a collection of data products a survey team has made publicly available, for a set of astronomical objects. Survey teams typically release new-and-improved data products with each release, but if you ran your analysis on a particular piece of data at a particular time, data releases allow you to view a specific time-stamped version of the survey products for a set of astronomical objects.</p> <p>The <a href=""http://datacentral.aao.gov.au/asvo/sov/"">Single Object Viewer</a>&nbsp;will always show the most current Data Release for a survey, but you can switch to view previous data releases using the <a class=""btn btn-default btn-xs dropdown-toggle"" type=""button"" data-toggle=""dropdown""> <span class=""fa fa-map-marker""></span>&nbsp; Data Releases </a> dropdown in the top right hand corner (e.g., see the&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/sov/sami/"">SAMI SOV</a>&nbsp;page).</p>";"2016-09-01 10:31:54.886408+08";"2016-11-24 11:17:20.913369+08";;FALSE;4
60;"Glossary";4;"data-central-glossary";"<p><span>This page contains a glossary of ADC-specific&nbsp;terminology, but it is by no means complete. I</span><span>f you come across a term you don&rsquo;t understand, or think we should include, please </span><a href=""http://datacentral.aao.gov.au/asvo/support/contact/"">contact us</a><span>.</span></p> <p>&nbsp;</p> <table class=""table table-hover table-bordered normal""> <tbody> <tr> <th>&nbsp;Term</th> <th>Description</th> <th>&nbsp;More info</th> </tr> <tr> <td>Astronomical Object</td> <td> <p class=""""><span>In FIDIA, our middleware package, the primary objects are astronomical objects, such as stars and galaxies, with data members (Traits) such as spectra, magnitudes and velocities. By presenting the properties and measurements of objects in this way, we simplify analysis and visualisation by providing a uniform representation of an astrophysical object's characteristics. </span>&nbsp;</p> </td> <td>&nbsp;</td> </tr> <tr> <td><strong>Branch</strong></td> <td><span>Branches represent different analysis pipelines for a Trait.</span></td> <td><a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-what-is-a-branch/"">What is a Branch? </a></td> </tr> <tr> <td>Data Model</td> <td><span>The description of the structure and organization of the data in a database. The data model describes the relationships between pieces of data.&nbsp;To view the schema, use the Schema Browser tool.</span></td> <td><a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-data-model/"">Data Model</a>&nbsp;</td> </tr> <tr> <td>Data Release</td> <td> <p><span><span><span>The formal release of Survey&nbsp;data to the public.&nbsp;</span></span></span><span><span>Each Data Release is associated with a journal article provided by the Survey teams that describes changes from the previous release.&nbsp;</span></span></p> </td> <td><a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-what-is-a-data-release/"">What is a Data Release?</a></td> </tr> <tr> <td>&nbsp;FIDIA</td> <td>FIDIA stands for ""Format Independent Data Interface for Astronomy."" We use FIDIA as the&nbsp;middleware package (effectively, as a high-level data model) to provide a uniform interface to the&nbsp;heterogeneous&nbsp;set of data provided by the survey teams.&nbsp;</td> <td><a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-a-format-independent-data-interface-for-astronomy-fidia/"">A Format Independent Data Interface for Astronomy: FIDIA </a></td> </tr> <tr> <td>Property</td> <td>Properties are the quantities associated with traits e.g., <ul> <li>Units</li> <li>Value</li> <li>Description</li> <li>etc</li> </ul> </td> <td>&nbsp;</td> </tr> <tr> <td>Sample</td> <td>Samples define collections of AstroObjects, which may&nbsp;be from multiple surveys.&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td>Survey</td> <td>A&nbsp;collection of AstroObjects as defined by the survey team. Each AstroObject contains a set of survey-defined traits (derived properties and data products).&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td>Trait</td> <td> <p>Traits can be thought of a data products or derived properties. They are essentially the quantities associated with AstroObjects. The type of AstroObject (star, galaxy, quasar, group etc) defines the&nbsp;standardised vocabulary of Traits that an astronomer might expect to find for each, reducing the need to troll through a schema browser.</p> </td> <td>&nbsp;</td> </tr> <tr> <td>Version</td> <td><span><span>A time-stamped capture&nbsp;of a Branch. Versions are useful in implementing bug fixes or new features, but do not require a full Data Release.</span></span></td> <td>&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-what-is-a-version/"">What is a Version?</a></td> </tr> </tbody> </table>";"2016-11-22 09:23:32.981209+08";"2016-11-24 11:17:24.749746+08";;FALSE;5
25;"How are data organised in the Single Object Viewer?";1;"sov-how-are-data-organised-in-the-single-object-viewer";"<p>Surveys hosted at ADC&nbsp;are classified as&nbsp;<code>samples</code>&nbsp;containing&nbsp;<code>astronomical objects</code>. Within the SOV, data are organised hierarchically, according to the following structure:</p> <dl class=""""> <dt></dt> <dt> <p><strong>survey/</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Available survey objects, products, schema browser etc.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/"">sov/sami/</a></p> </dd> <dt> <p><strong>survey/galaxy</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Available data for the object 'galaxy'.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/"">sov/sami/24433/</a></p> </dd> <dt> <p><strong>survey/galaxy/trait/</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Displays an on-the-fly rendering of the property (if sensible). Download in a variety of formats [fits, json, csv].</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729"">sov/sami/24433/line_emission_map-OII3729</a></p> </dd> <dt> <p><strong>survey/galaxy/trait/property</strong></p> </dt> <dd> <p style=""padding-left: 30px;"">Displays a list of the properties&nbsp;belonging to the trait.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3729/value/"">sov/sami/24433/line_emission_map-OII3729/value/</a></p> </dd> </dl> <p>You can read more about our data model <a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-data-model/"">here</a>, or our middleware python package, FIDIA&nbsp;<a href=""http://datacentral.aao.gov.au/asvo/docs/articles/data-central-a-format-independent-data-interface-for-astronomy-fidia/"">here</a>. Alternatively, browse the Data Access articles <a href=""http://datacentral.aao.gov.au/asvo/docs/help-center/data-access/"">here</a>.&nbsp;</p> <p>&nbsp;</p>";"2016-08-31 14:28:35.48437+08";"2016-11-21 14:38:46.621666+08";;FALSE;0
54;"How are data organised in the Schema Browser?";3;"schema-browser-how-are-data-organised-in-the-schema-browser";"<p><span>The Schema Browser reflects the&nbsp;tree-like organisational structure we've adopted here at ADC. The schema displays data products and derived properties&nbsp;provided for a particular survey. E.g., </span><a href=""http://datacentral.aao.gov.au/asvo/schema-browser/sami/"">schema-browser/sami/</a><span>&nbsp;is the schema browser for the SAMI survey-team derived products and properties.&nbsp;</span></p> <p><strong>survey/</strong></p> <p style=""padding-left: 30px;"">Available survey objects, products, schema browser etc.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/schema-browser/sami/"">schema-browser/sami/</a></p> <p><strong>survey/trait/</strong></p> <p style=""padding-left: 30px;"">Displays&nbsp;documentation, high-level descriptions of trait properties, downloadable format information and a table of all available branches and versions for this trait.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/schema-browser/sami/line_emission_map-OII3726/"">schema-browser/sami/line_emission_map-OII3726/</a></p> <p><strong>survey/galaxy/trait/property</strong></p> <p style=""padding-left: 30px;"">Displays the schema for the property.</p> <p style=""padding-left: 30px;"">e.g, <a href=""http://datacentral.aao.gov.au/asvo/schema-browser/sami/line_emission_map-OII3726/lzifu_input_redshift/"">schema-browser/sami/line_emission_map-OII3726/lzifu_input_redshift/</a></p> <p>&nbsp;</p> <p>&nbsp;</p>";"2016-10-06 10:12:00.289949+08";"2016-11-21 14:53:49.512663+08";;FALSE;0
59;"How can I switch branch and version in the SOV?";1;"sov-how-can-i-switch-branch-and-version-in-the-sov";"<p><span>The </span><a href=""http://datacentral.aao.gov.au/asvo/sov/"">Single Object Viewer</a><span>&nbsp;will always show the default branch, but you can switch to view other branches&nbsp;using the </span><a class=""btn btn-default btn-xs dropdown-toggle"" type=""button"" data-toggle=""dropdown""><span class=""fa fa-code-fork""></span>&nbsp; Branches </a><span>dropdown in the top right hand corner of the page (e.g., see the&nbsp;</span><a href=""http://datacentral.aao.gov.au/asvo/sov/sami/24433/line_emission_map-OII3726/"">SAMI 24433 Line Emission Map &mdash; Oii3726</a><span>&nbsp;page).</span></p> <p>&nbsp;</p>";"2016-11-21 15:01:57.022582+08";"2016-11-21 15:01:57.02261+08";;FALSE;0
10;"What is the Single Object Viewer?";1;"sov-what-is-the-single-object-viewer";"<p>The Single Object Viewer (<a href=""http://datacentral.aao.gov.au/asvo/sov/"">SOV</a>)&nbsp;is a portal to all survey data hosted at ADC. Surveys are a collection of astronomical objects. Each astronomical object's components are organised into a tree-like structure, allowing you to discover derived properties and data products, along with any associated meta-data.</p> <p>For certain types of data product (e.g., line maps) you can interact with the data directly in your browser. You can also download data products in fits format to work with offline using your favourite astronomy visualization software.</p> <p>To view more information about a particular survey's data products and derived properties, visit the&nbsp;<a style=""box-sizing: border-box; color: #4078c0; text-decoration: none; background-color: transparent;"" href=""../../../schema/"">Schema Browser</a>.</p>";"2016-08-29 16:18:54.912809+08";"2016-11-23 14:56:25.493968+08";;FALSE;0
63;"SAMI in a nutshell";110;"sami-sami-in-a-nutshell";"<p>&nbsp;The Sydney-AAO Multi-object Integral field spectrograph (SAMI) is mounted at the prime focus on the Anglo-Australian Telescope that provides a 1 degree diameter field of view. SAMI uses 13 fused fibre bundles (Hexabundles) with 73% fill factor. Each bundle contains 61 fibres of 1.6 arcsec diameter resulting in each integral field unit (IFU) having a diameter of 15 arcsec. See <a href=""http://adsabs.harvard.edu/abs/2012MNRAS.421..872C"">Croom at al. (2012)</a> for more info.</p> <p><span>&nbsp;</span></p> <p><img class=""img-responsive"" src=""../../../../static/documentation/img/sami/sami_bundles.jpg"" /></p> <p><span><em>The fibre core arrangement for one of the SAMI fibre IFUs. Each fibre has a core diameter of 105&mu;m, with the cladding thinned to 110&plusmn;1 &mu;m over the first 50 mm of each fibre. <a href=""http://adsabs.harvard.edu/abs/2015MNRAS.446.1551S"">(Sharp et al. 2014)</a>.</em></span></p> <p>The IFUs, as well as 26 sky fibres, are plugged into pre-drilled plates using magnetic connectors. SAMI fibres are fed to the double-beam <a href=""https://www.aao.gov.au/science/instruments/current/AAOmega"">AAOmega spectrograph</a>. AAOmega allows a range of different resolutions and wavelength ranges. For the SAMI Galaxy survey we use the 570V grating at 3700-5700A giving a resolution of R=1730 ($&sigma;=74$ km/s), and the R1000 grating from 6250-7350A giving a resolution of R=4500 ($&sigma; =29$ km/s).</p> <p>&nbsp;</p> <p><img class=""img-responsive"" src=""../../../../static/documentation/img/sami/Wavelength_coverage.jpg"" /></p> <p><em>Wavelength coverage vs. redshift for the current default SAMI configuration compared to key spectral lines. The red and blue regions indicate the wavelength coverage of the red and blue arms of AAOmega. Magenta lines mark the redshift boundaries for the primary sample. <a href=""http://adsabs.harvard.edu/abs/2015MNRAS.447.2857B"">(Bryant et al. 2014)</a>.</em></p>";"2016-11-24 10:21:13.225255+08";"2016-11-24 11:15:23.467391+08";;FALSE;0
64;"SAMI Survey Target selection";110;"sami-sami-survey-target-selection";"<div id=""toc"" class=""toc""> <h5 class=""toc-title"">Page Contents</h5> <ul> <li class=""toc-level-1""><a href=""#The_SAMI-GAMA_sample"">The SAMI-GAMA sample</a></li> <li class=""toc-level-1""><a href=""#The_SAMI_cluster_sample"">The SAMI cluster sample</a></li> </ul> </div> <p>&nbsp;</p> <p>The SAMI Galaxy Survey is designed to address the following three key questions about galaxy evolution:</p> <ul> <li> <p>What is the physical role of environment in galaxy evolution?</p> </li> <li> <p>What is the interplay between gas flows and galaxy evolution?</p> </li> <li> <p>How are mass and angular momentum built up in galaxies?</p> </li> </ul> <p>This naturally requires covering a broad range of stellar masses and environments. To reach this goal the galaxies targeted by the SAMI Galaxy Survey have been selected from two distinct parent samples: the <a href=""http://gama-survey.org"">GAMA survey</a> and a sample of eight nearby clusters. The clusters were added to guarantee that we map all galactic environments and do not miss the most dense structures, which are undersampled in the GAMA survey.</p> <h2 id=""The_SAMI-GAMA_sample"">The SAMI-GAMA sample</h2> <p>Non-cluster SAMI targets have been extracted from the three equatorial fields included in the GAMA redshift survey. In addition to providing a unique maps of the large scale structure of the local Universe, GAMA brings together a unique suite of multi wavelength data from the ultraviolet to the far-infrared increasing the legacy value of SAMI. The SAMI galaxies selected from the GAMA survey consist of four volume-limited samples from a stepped series of stellar mass cuts in redshift bands, along with additional dwarf galaxy candidates with low stellar mass and low redshift. Due to tiling constraints and source distributions some field configurations may not have 12 primary targets, therefore filler targets were also defined. The Table below outlines the selection criteria used to isolate primary and secondary SAMI targets. Redshifts are adjusted to the <a href=""http://adsabs.harvard.edu/abs/2000ApJ...530..625T"">Tonry et al. 2000</a> flow model.</p> <table class=""table table-bordered table-condensed""> <thead> <tr class=""active""> <th align=""left"">Redshift Range</th> <th>$\log(M_{*}/M_{sun})$</th> </tr> </thead> <tbody> <tr class=""even""> <td align=""left""><strong>Primary Targets</strong></td> <td>&nbsp;</td> </tr> <tr class=""odd""> <td align=""left"">0.004$&lt;z\leq$0.02</td> <td>$\geq$7+60z</td> </tr> <tr class=""even""> <td align=""left"">0.02$&lt;z\leq$0.03</td> <td>$\geq$8.2</td> </tr> <tr class=""odd""> <td align=""left"">0.03$&lt;z\leq$0.045</td> <td>$\geq$9.0</td> </tr> <tr class=""even""> <td align=""left"">0.045$&lt;z\leq$0.06</td> <td>$\geq$10.0</td> </tr> <tr class=""odd""> <td align=""left"">0.06$&lt;z\leq$0.095</td> <td>$\geq$10.9</td> </tr> <tr class=""even""> <td align=""left""><strong>Filler Targets</strong></td> <td>&nbsp;</td> </tr> <tr class=""odd""> <td align=""left"">0.03$&lt;z\leq$0.045</td> <td>$\geq$8.6</td> </tr> <tr class=""even""> <td align=""left"">0.045$&lt;z\leq$0.06</td> <td>$\geq$9.4</td> </tr> <tr class=""odd""> <td align=""left"">0.06$&lt;z\leq$0.095</td> <td>$\geq$10.3</td> </tr> <tr class=""even""> <td align=""left"">0.095$&lt;z\leq$0.115</td> <td>$\geq$10.9</td> </tr> </tbody> </table> <p>The total number of galaxies included in the sample is composed of 2404 main and 2513 filler targets. More details on the sample selection can be found in <a href=""http://adsabs.harvard.edu/abs/2015MNRAS.447.2857B"">Bryant et al. (2015)</a>.</p> <p><strong>[ADD FIGURE]</strong></p> <h2 id=""The_SAMI_cluster_sample"">The SAMI cluster sample</h2> <p>The environment of the GAMA-selected galaxies ranges from field galaxies to groups, with very few having halo masses typical of clusters of galaxies. To extend the survey to higher mass environments therefore requires the addition of galaxy clusters selected to have virial masses $&gt;10^{14} \rm M_{sun}$. Clusters were chosen with an R.A. range of 22-03hrs so that they are observable in the second half of the year, as the GAMA fields are all observable in the first half of the year. The 8 clusters in the SAMI cluster sample are listed below. They were picked to overlap with either the SDSS or 2dFGRS to make use of the existing redshift catalogues for selection of cluster members. We measured additional redshifts using AAOmega fed by the 2dF multi-object fibre-feed for cluster candidates that have r$&lt;$19.4 mag to reach 90% completeness in the cluster fields.</p> <table class=""table table-bordered table-condensed""> <thead> <tr class=""active""> <th align=""left"">Cluster name</th> <th>RA (deg)</th> <th>Dec (deg)</th> <th>z</th> <th>Virial mass ($10^{14}\rm M_{sun}$)</th> </tr> </thead> <tbody> <tr class=""even""> <td align=""left"">EDCC0442</td> <td>6.381</td> <td>-33.047</td> <td>0.0494</td> <td>4.5$\pm$0.9</td> </tr> <tr class=""odd""> <td align=""left"">Abell0085</td> <td>10.460</td> <td>-9.303</td> <td>0.0556</td> <td>15.4$\pm$1.9</td> </tr> <tr class=""even""> <td align=""left"">Abell0119</td> <td>14.067</td> <td>&minus;1.255</td> <td>0.0442</td> <td>10.1$\pm$1.1</td> </tr> <tr class=""odd""> <td align=""left"">Abell0168</td> <td>18.740</td> <td>0.431</td> <td>0.0448</td> <td>3.2$\pm$0.5</td> </tr> <tr class=""even""> <td align=""left"">Abell2399</td> <td>329.389</td> <td>&minus;7.794</td> <td>0.0582</td> <td>6.0$\pm$0.8</td> </tr> <tr class=""odd""> <td align=""left"">Abell3880</td> <td>336.977</td> <td>&minus;30.575</td> <td>0.0579</td> <td>2.8$\pm$0.6</td> </tr> <tr class=""even""> <td align=""left"">APMCC0917</td> <td>355.398</td> <td>&minus;29.236</td> <td>0.0509</td> <td>2.0$\pm$0.5</td> </tr> <tr class=""odd""> <td align=""left"">Abell4038</td> <td>356.895</td> <td>&minus;28.125</td> <td>0.0297</td> <td>2.9$\pm$0.6</td> </tr> </tbody> </table>";"2016-11-24 10:21:27.224988+08";"2016-11-24 11:15:35.069232+08";;FALSE;1
47;"Data Reduction";110;"sami-data-reduction";"<h5 class=""toc-title"">Page Contents</h5> <ul> <li class=""toc-level-1""> <p><a href=""#Overview"">Overview</a></p> </li> <li class=""toc-level-1""> <p><a href=""#Raw_data_to_RSS_frames"">Raw data to RSS frames</a></p> </li> <li class=""toc-level-1""> <p><a href=""#RSS_frames_to_cubes"">RSS frames to cubes</a></p> </li> </ul> <p>&nbsp;</p> <p>SAMI data reduction divides neatly into two overarching stages; from raw data straight off the telescope to row stacked spectra (RSS), and from RSS frames to individual galaxy data cubes. RSS frames are two-dimensional arrays containing one-dimensional, wavelength calibrated spectra from all SAMI fibres for a single exposure (RSS frames represent an intermediate step in the data reduction process and are not included as part of the DR 1 release). Data cubes are then formed by extracting all spectra for a given galaxy from each of the contributing RSS frames, drizzling, combining, then resampling onto a regular grid.</p> <h2 id=""Raw_data_to_RSS_frames"">Raw data to RSS frames</h2> <p>The follow steps are applied by 2dfDR to individual raw frames to produce RSS frames.</p> <ol> <li> <p><strong>Bias, dark and overscan subtraction</strong>: Bias and dark frames are subtracted to correct errant CCD pixels. This step is applied to the blue arm data only, as the red AAOmega CCD was much less affected by defects. Both CCDs were upgraded in 2014, making this step largely redundant. however is it still applied to post-upgrade blue arm observations for consistency with previous data. An overscan correction is also applied, subtracting the bias level in each frame.</p> </li> <li> <p><strong>Flat-fielding</strong>: Each frame is divided by a detector flat that is generated by averaging (typically $&gt;30$) fibre flats for which the spectrograph has been defocussed so that the illumination is relatively uniform. These frames are then filtered to remove large-scale variations, leaving only smaller-scale pixel-to-pixel flat-field variations. Charge spots due to cosmic rays are removed from each individual science frame using a tuned implementation of the LaCosmic routine.</p> </li> <li> <p><strong>Tramline map construction</strong>: Fibre locations are traced across the detector, generating a so-called <em>tramline map</em> giving the pixel-by-pixel [x,y] location of each fibre. This is performed using a fibre flat-field frame taken using a quartz-halogen lamp that illuminates a white-spot on the AAT dome. The fibre peaks are identified and fitted approximately using a quadratic fit to the 3 pixels around each peak. Then as a second stage we implement an algorithm that assumes a Gaussian fibre profile (a good approximation to SAMI fibres in AAOmega) and fits five Gaussians (the central one and two either side) to precisely determine both the centre and width of the fibre profile.</p> </li> <li> <p><strong>Spectral extraction and flat-fielding</strong>: Flux from the 2D image is extracted to generate a 1D spectrum for each fibre. An optimal extraction (see <a href=""http://adsabs.harvard.edu/abs/2010PASA...27...91S"">Sharp &amp; Birchall 2010</a>) is performed to fit the flux amplitudes perpendicular to the dispersion axis. Gaussian profiles are fit, holding the centre and width constant (based on the tramline and fibre width maps measured above) and fitting all 819 fibres simultaneously. Following extraction, the 1D spectra are divided by an extracted and normalised 1D dome lamp flat-field spectrum, which removes residual fibre-to-fibre variations in spectral response.</p> </li> <li> <p><strong>Wavelength calibration</strong>: Emission lines in a CuAr arc lamp exposure are identified in extracted 1D spectra and matched to line-lists with a 3$^\mathrm{rd}$ order polynomial for each fibre solution.</p> </li> <li> <p><strong>Fibre throughput correction</strong>: Fibre throughputs were calibrated primarily from the relative strength of twilight flat-field frames. If no twilight frame was observed for a given field, a dome flat-field frame was used. These throughput values were then used for subtraction of the night sky spectrum. If the sky residuals after sky subtraction (see below) were large, the fibre throughputs were remeasured using the integrated flux in the night sky lines. If all sky lines were affected by bad pixels (typically only an issue for the blue CCD, which covers only a single sky line), then the mean fibre throughputs, derived from all other frames for this field, were adopted. The sky subtraction was then repeated with the revised throughput values.</p> </li> <li> <p><strong>Sky subtraction</strong>: The sky spectrum is measured from 26 dedicated sky fibres, taking a median spectrum after throughput correction, and subtracted from all spectra.</p> </li> </ol> <p>The above steps result in RSS frames consisting of 819 wavelength-calibrated, flat-fielded, one-dimensional spectra.</p> <h2 id=""RSS_frames_to_cubes"">RSS frames to cubes</h2> <p>The 819 fibres on each object RSS frame constitute: 12 hexabundles (61-fibre IFUs) targeted on SAMI Galaxy Survey galaxy targets, 1 hexabundle targeted on a secondary standard star and 26 sky fibres (which are not used beyond the steps outlined above). Each galaxy field (i.e. set of 12 galaxy targets and one secondary standard star) is observed at least 6 (and typically 7) times. In addition to galaxy object frames, several exposures containing only a single spectrophotometric standard star centred in one hexabundle are also observed throughout the night.</p> <p>The process of combining and reconstructing these RSS frames into three-dimensional data cubes of individual galaxies is accomplished using the <em>sami.py</em> data reduction package. In addition, the <em>sami</em> package applies a telluric correction and absolute flux calibration step to each RSS frame and a final flux calibration step to each output data cube.</p> <ol> <li> <p><strong>Initial flux calibration</strong>: Correct for the large-scale (in wavelength) extinction by the atmosphere at Siding Spring Observatory at the observed airmass.</p> </li> <li> <p><strong>Primary flux calibration</strong>: Extract the spectrum for each spectrophotometric standard star observed (accounting for light lost between fibres) and compare to the known stellar spectrum to determine the transfer function. Multiply galaxy RSS frames by the transfer function derived from the spectrophotometric observation closest in time to the galaxy frame.</p> </li> <li> <p><strong>Telluric correction</strong>: Extract the spectrum for the secondary standard star (again accounting for light lost between fibres), selected to be a relatively featureless F-dwarf based on the colours. Using a linear fit across the telluric regions (6850--6960 A and 7130--7360 A), determine a telluric correction, and divide all galaxy spectra by this correction.</p> </li> <li> <p><strong>Secondary flux calibration</strong>: Determine the observed g-band magnitude of the secondary standard star from its extracted spectrum, and compare to the catalogue g-band magnitude for the corresponding star. Rescale all galaxy spectra in the frame by this ratio.</p> </li> <li> <p><strong>Centering</strong>: Fit the centroids of each of the 12 galaxies in a frame using a two-dimensional Gaussian and a simple empirical model describing the telescope offset and atmospheric refraction. Repeat for all frames for a given galaxy field to measure the variation in centroid for each galaxy from frame to frame. Align each individual galaxy across frames using the measured centroids.</p> </li> <li> <p><strong>Cube creation</strong>: Each frame is drizzled onto a regular 0.5 arc second-square spaxel grid. The flux in each output spaxel was taken to be the mean of the flux in each input fibre, weighted by the fractional spatial overlap of that fibre with the spaxel. To regain some of the spatial resolution that would otherwise be lost in convolving the 1.6 arc second fibres with 0.5 arc second spaxels, the overlaps were calculated using a fibre footprint with only an 0.8 arc second diameter. The centroid of a galaxy varies as a function of wavelength due to atmospheric refraction --- this effect was corrected for by re-calculating the drizzle locations when the expected shift due to atmospheric diffraction exceeded 1/50th of a spaxel. The derived flux cube is then multiplied by a weight cube (see below), such that the output flux cube is in units of 10$^{-16}$ erg s$^{-1}$ cm$^{-2}$.</p> </li> <li> <p><strong>Final flux calibration</strong>: The spectrum of the secondary standard star was re-extracted from the final data cube, using a Moffat profile fit. The g-band magnitude was again calculated, and a final scaling relative to the catalogue value of the star was applied to all galaxy cubes from the same field. The total effective seeing of all galaxies in the field was also determined from the Moffat fit.</p> </li> </ol> <p>The above data reduction is applied simultaneously to both blue and red arm data, with separate blue and red data cubes produced as output. The secondary and final flux calibration scaling values are derived from the blue arm data but are applied to both arms.</p>";"2016-09-05 14:07:21.003932+08";"2016-11-24 11:15:49.524828+08";;FALSE;2
65;"Data Cube structure";110;"sami-data-cube-structure";"<p>SAMI data cubes consist of four main extensions: flux (primary), variance, weight map and covariance hypercube, as well as accompanying metadata. Here we describe the basic format of each of these data products.</p> <ul> <li> <p><strong>Flux cube</strong>: The primary SAMI data product --- a $2048\times50\times50$ array, where the long axis corresponds to wavelength and the two short axes correspond to the x and y spatial direction respectively. The pixel scale on the two spatial axes is 0.5 arc seconds per pixel. For blue cubes the wavelength axis pixel scale is 1.04 A per pixel, for the red cubes the wavelength scale is 0.57 A per pixel. The flux cubes are in units of 10$^{-16}$ erg s$^{-1}$ cm$^{-2}$, with the weight map already applied.</p> </li> <li> <p><strong>Variance cube</strong>: A $2048\times50\times50$ array, where the value of each pixel is the variance of the corresponding pixel in the flux cube. Variances are propagated throughout the reduction pipeline, from the raw frames through to the final data cubes.</p> </li> <li> <p><strong>Weight map</strong>: A $2048\times50\times50$ array, where the value of each pixel is the effective exposure time of the corresponding pixel in the flux cube. . The weight map is calculated using the drizzle algorithm. Considering each input fibre core in turn, we calculate the overlap area of the input fibre core with each element of a predefined regular grid of output spaxels. The fractional area of an input fibre core covering each output spaxel dictates how the flux should be redistributed to each output spaxel. This fractional area provides a weight for each output spaxel which represents the relative exposure of each output spaxel. Output spaxels that do not sit within any input fibre cores will be assigned a weight of zero. Output spaxels that fall on the border between multiple input cores will have a weighted contribution from each core, but the total weight for such spaxels will not exceed unity. To place dithered data onto the regularised grid, we simply recalculate the overlaps after perturbing the baseline position (by the known telescope offset) of the input fibre cores relative to the initial reference position. The final weights are therefore normalised to the number of contributing frames for a given object. Note that the flux cubes, by default, have the weight map pre-applied. When combining data, cubes should first be multiplied by their weight maps, the data and individual weight maps summed, and the summed data finally divided by the new weight map to preserve the correct flux calibration.</p> </li> <li> <p><strong>Covariance hypercube</strong>: A $2048\times50\times50\times5\times5$ array, where each $5\times5$ sub-array contains the spatial covariance of the given pixel in the flux array with all surrounding pixels. The covariance array contains the <em>relative</em> covariance, and each $5\times5$ sub-array should be multiplied by the corresponding variance value to recover the true covariance. See below for details on the format and reconstruction of the full covariance array.</p> </li> </ul> <p><strong>Metadata</strong></p> <p>The fits header of the flux cube contains key metadata describing the data, observations and reduction process. Along with standard fits header keywords, the cube header contains:</p> <ul> <li> <p>HGCUBING: Mercurial changeset ID of the <em>sami.py</em> Python package used to generate the cube.</p> </li> <li> <p>RSS_FILE <em>n</em>: Fits file name of the RSS frames contributing to the data cube.</p> </li> <li> <p>PLATEID and LABEL: Identifiers for the SAMI field</p> </li> <li> <p>STDNAME: SAMI ID of the secondary standard star for the field</p> </li> <li> <p>BUNIT: Units of the flux cube.</p> </li> <li> <p>PSFFWHM: Full-width half-maximum of the Moffat profile fit to the standard star for the field.</p> </li> <li> <p>PSFALPHA and PSFBETA: Parameters of the Moffat profile fit to the standard star in the field.</p> </li> <li> <p>RESCALE: Flux rescaling applied to the cube, derived from the ratio of the observed and catalogue g-band magnitudes of the secondary standard star.</p> </li> </ul> <h2>An additional note on covariance</h2> <p>Because each input fibre overlaps with more than one output spaxel, the flux measurements in the datacubes are covariant with nearby spaxels. This is a generic issue for any data that is resampled onto a grid. A crucial consequence is that, when spectra from two or more spaxels are summed, the variance of the summed spectrum is not equal to the sum of the variances of the individual spectra. Similarly, a model fit to the datacube would need to account for the covariance between spaxels.</p> <p>The spatial covariance between spaxels is stored in the covariance array for each cube. Spatial covariance introduced by the resampling process is the dominant but not exclusive source of covariance in SAMI data. We do not track the spectral covariance or any spatial covariance introduced during the fibre extraction process, but these are negligible with respect to the tracked covariance.</p> <p>The covariance is stored in a condensed form to reduce the size of the output data cubes. Each covariance hypercube is stored as a 50$\times$50$\times$5$\times$5$\times$$N$ array, where $N$ is the number of wavelength slices for which the covariance has been calculated and stored. For each wavelength slice $m$, the value of COVAR[$i,j,k,l,m$] records the <em>relative</em> covariance between the spaxel $(i,j)$ and one nearby spaxel, for data that have been weighted by the relative exposure times. This value should be multiplied by the weighted variance of the $(i,j)^{\rm th}$ spaxel to recover the true covariance. The central value in the $k$ and $l$ directions ($k=2$, $l=2$ for 0-indexed arrays) corresponds to the relative covariance of the $(i,j)^{\rm th}$ spaxel with itself, which is always equal to unity. Surrounding values give the relative covariance of the $(i,j)^{\rm th}$ spaxel with all locations up to two spaxels away. Covariance on larger scales is negligible. The positions of the wavelength slices at which the covariance was calculated were chosen to accurately sample the regions where the covariance changes most rapidly, which occurs where the drizzle locations were recalculated due to atmospheric dispersion. The full covariance array can be reconstructed using the <em>reconstruct_covariance</em> function in the <em>sami.dr.binning</em> module of the <em>sami.py</em> Python package.</p>";"2016-11-24 10:21:50.63988+08";"2016-11-24 11:16:02.181405+08";;FALSE;3
66;"LZIFU Data Products";110;"sami-lzifu-data-products";"<h5 class=""toc-title"">Page Contents&nbsp;</h5> <ul> <li class=""toc-level-1""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Spectral_Analysis"">Spectral Analysis</a> <ul> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Continuum_Fitting"">Continuum Fitting</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Emission_Line_Fitting"">Emission Line Fitting</a></li> </ul> </li> <li class=""toc-level-1""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Data_Quality"">Data Quality</a> <ul> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Errors_in_the_line_fits"">Errors in the line fits</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Systematic_errors_from_the_continuum_fit"">Systematic errors from the continuum fit</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Non-zero_covariance"">Non-zero covariance</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Errors_of_OII372631_doublets"">Errors of [OII]3726,31 doublets</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Quality_Flags"">Quality Flags</a></li> </ul> </li> <li class=""toc-level-1""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Data_Products"">Data Products</a> <ul> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Kinematics_maps"">Kinematics maps</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Line_flux_maps"">Line flux maps</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Equivalent_widths_maps"">Equivalent widths maps</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Extinction_Maps"">Extinction Maps</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Star_Formation_Rate_Masks"">Star Formation Rate Masks</a></li> <li class=""toc-level-2""><a href=""http://sami-survey.org/wiki/lzifu-data-products-dr1#Star_Formation_Rate_Maps"">Star Formation Rate Maps</a></li> </ul> </li> </ul> <h1 id=""Spectral_Analysis"">Spectral Analysis</h1> <p>The main goal of LZIFU (LaZy-IFU, <a href=""http://adsabs.harvard.edu/abs/2016Ap%26SS.361..280H"">Ho et al.2016</a>) is to extract emission line maps and kinematic maps from SAMI data cubes. We achieved this in two steps. On a spaxel-to-spaxel basis, we first model and subtract the continuum, then fit emission lines to the continuum-free spectrum. We briefly introduce the procedures below. A full description of the pipeline LZIFU is presented in <a href=""http://adsabs.harvard.edu/abs/2016Ap%26SS.361..280H"">Ho et al.2016</a>.</p> <h2 id=""Continuum_Fitting"">Continuum Fitting</h2> <p>To perform a full-spectrum modeling of the continuum at a given spaxel, LZIFU first convolves the blue and red spectra to a common spectral resolution (i.e., the blue resolution) and then stitches the two spectra together. The merged spectrum is sent to the penalized pixel-fitting routine (pPXF; <a href=""http://adsabs.harvard.edu/abs/2004PASP..116..138C"">Cappellari &amp; Emsellem 2004</a>) for modeling the continuum. Only channels not contaminated by strong sky lines or optical emission lines are included in the fitting process. In addition to bad channels rejected by the data reduction pipeline, we mask out the vicinity ($\rm\pm10~A$) of strong sky lines<sup><a id=""ref1"" href=""#fn1"">1</a></sup>, and those at $\rm 40~A$ (full-width) around common emission lines<sup><a id=""ref2"" href=""#fn2"">2</a></sup>. Only channels between $\rm3700~A$ and $6950\times (1+z)~\rm A$ are considered due to the limited spectral coverage of the stellar templates.</p> <p>In this release, we adopt the MILES templates with the Salpeter IMF of four metallicities ([M/H] = $-0.71$, $-0.40$, 0 and $+0.22$) and 13 ages (equally spaced logarithmically from 63.1Myr to 15.8Gyr) from <a href=""http://adsabs.harvard.edu/abs/2010MNRAS.404.1639V"">Vazdekis et al. (2010)</a>. Additive Legendre Polynomials (orders 2 to 10) are also included to fit simultaneously with the stellar templates. To reject potential bad channels, we iterate the continuum fit while imposing a robust-sigma clipping (5$\sigma$. Note that this is different from what the standard CLEAN keyword in pPXF does.</p> <p>These templates are at a slightly lower spectral resolution than the red arm of our spectra; therefore in low stellar velocity dispersion galaxies ($\sigma&lt;$30 km s$^{-1}$), we may incorrectly subtract the H$\alpha$~absorption. However, most of these low stellar velocity dispersion galaxies have strong emission lines, so this systematic error is not likely to have a big effect beyond what is accounted for in our Balmer flux error corrections.</p> <p>Continuum modeling has not been the main focus of LZIFU, and a more careful continuum fit should be done for stellar analysis. Here, our major goals are to (1) correct for Balmer absorptions, and (2) acquire reasonably flat (continuum-free) spectra to measure properties of emission lines.</p> <h2 id=""Emission_Line_Fitting"">Emission Line Fitting</h2> <p>After removing the continuum, LZIFU models emission lines as Gaussians and performs a bounded-value nonlinear least-squares fit using the Levenberg-Marquardt least-squares method implemented in IDL (MPFIT; <a href=""http://adsabs.harvard.edu/abs/2009ASPC..411..251M"">Markwardt 2009</a>). Only channels $\pm20\rm\AA$ around line centers, as inferred from the galaxy redshifts, are included in the fitting process. Every emission line is modeled with a single Gaussian (multiple components fits will be provided in future releases). All the lines are fit simultaneously and the kinematic component is constrained to share the same velocity and velocity dispersion.</p> <p>In total, we fit 11 strong optical lines simultaneously, [OII]3726,29, H$\beta$, [OIII]4959,5007, [OI]6300, [NII]6548,83, H$\alpha$, and [SII]6716,31. [OIII]4959 and [NII]6548 are both constrained to be one-third in amplitude (and flux) of [OIII]5007 and [NII]6583, respectively. We do not produce line maps for these two lines.</p> <h1 id=""Data_Quality"">Data Quality</h1> <h2 id=""Errors_in_the_line_fits"">Errors in the line fits</h2> <p>One sigma errors of line fluxes (except for Balmer lines, see below), velocities, and velocity dispersions are taken straight from MPFIT, which uses the Levenberg-Marquardt technique to solve the maximum likelihood problem, and the Jacobian matrix of the line model to estimate the covariance matrix for parameters. We have tested the robustness of MPFIT through Monte Carlo simulations. In the absence of any systematic errors, such as those from continuum subtraction or those from variance of the data, the one sigma errors returned by LZIFU (from MPFIT) are robust. We discuss in the following sections some of the possible systematic errors we have identified that you should be aware of, some of which have been incorporated into the line flux error extensions.</p> <h2 id=""Systematic_errors_from_the_continuum_fit"">Systematic errors from the continuum fit</h2> <p>Due to the way the continuum is fit and LZIFU is set up, the best-fit continua are assumed to be noise- and error-free by the emission line fitting code. Our Monte Carlo simulations reveal, unsurprisingly, that there is some systematic contribution to the true line-fitting errors that comes from the continuum, unidentified by LZIFU. This systematic effect is negligible in galaxies with strong emission lines and weak continua, but has a progressively larger effect as the continuum flux increases relative to the emission line fluxes. Errors are predominantly due to the Balmer absorption features, and therefore affect the H$\alpha$ and H$\beta$ emission line fluxes most strongly. This has the effect that raw MPFIT errors on the Balmer line fluxes can be significant underestimates in some cases. In order to avoid this, we have incorporated an estimate of this error into the H$\alpha$ and H$\beta$ line flux error extensions, described here.</p> <p>Balmer absorption in stellar populations is strongly correlated with the 4000$\AA$ break. We therefore estimate our errors on the Balmer absorption of the continuum using the errors on the Dn4000 index (which is measured by J. Moustakas' IDL routine <em>spectral_indices</em>). This error in the Balmer continuum absorption equivalent width is then proportional to the extra error translated to the emission line fluxes. The Balmer continuum absorption is spread out over a wide spectral range, so only a fraction of it (based on the emission line width) is propagated to the emission line flux. We therefore use the equations:</p> <p>$\delta_{Hx,tot}^2 = \delta_{Hx,MPFIT}^2 + (A_{Hx} \delta_{Hx,contEW} f_{cont})^2$</p> <p>$A_{H\alpha} = 0.0504933 + 0.00100893 \times (6 \sigma) $</p> <p>$A_{H\beta} = 0.0258323 + 0.000802997 \times (6 \sigma) $</p> <p>where $\sigma$ is the velocity dispersion of the emission line, and $f_{cont}$ is the continuum level around the emission line, used to convert the equivalent width error into flux units. $A_{Hx}$ equations were calculated using the MILES stellar template libraries at typical ranges of metallicity, stellar velocity dispersion, and stellar population age.</p> <p>These new errors are incorporated in as the actual errors on the emission line fluxes for Balmer emission lines, and should be used as you would normally use errors. Now only a small fraction of fits ($\sim$3.5%) have Balmer decrements that are below 2.86 (expected for case B recombination) by more than one standard deviation.</p> <h2 id=""Non-zero_covariance"">Non-zero covariance</h2> <p>When a line is fit with more than one component, the fluxes of different components are highly correlated. Typically the correlation coefficients are negative because the total flux, the sum of all components, remains approximately the same. This means when summing the fluxes of two components together, the combined error is not the quadrature sum of the errors. The error of the sum should be taken directly from the first slice in MS2D, which takes the covariances into account.</p> <h2 id=""Errors_of_OII372631_doublets"">Errors of [OII]3726,31 doublets</h2> <p>In almost all lines, the wavelength separations between different lines are much larger than the spectral resolutions such that fluxes between different lines are independent of each other, i.e. the covariances are zero. This is not true for the [OII]3726,31 doublets. The doublets are marginally resolved by the blue spectrograph and therefore non-zero covariance can be important. Currently, the covariances are not reported and therefore directly summing the flux errors (of the two lines) in quadrature would overestimate the errors.</p> <p>In some cases where signal-to-noise ratio is poor, LZIFU would use only one Gaussian to model one of the lines and report zero flux for the other. In this case, the error on the line with zero flux would be NaN (parameter touches boundaries) and the error on the non-zero line will be a more representative estimate.</p> <p>Because the doublets are only marginally resolved, and the lines are usually at the very blue parts of the spectrograph, we highly recommend that you use only the summed flux for any analysis.</p> <h2 id=""Quality_Flags"">Quality Flags</h2> <p>Though the SAMI team has put every effort into making sure these data and the subsequent analysis are of high quality, there will always be some issues that may persist, such as bad sky subtraction or inconveniently-located cosmic rays, that could cause a given line to be fit incorrectly. Because we do not want to have to (nor do we want you to have to) look through each line fit for quality, we've also designed a number of quality flags that can be automatically triggered using a number of criteria.</p> <p>Each data structure has an extension called <em>QF</em>, a 2D map that lists the number of quality flags that were triggered by each spectrum.</p> <ul> <li> <p>0 indicates that no flags were triggered: that spectrum exhibits no suspicious behavior;</p> </li> <li> <p>1 indicates that only one of the seven indicators of poor fits were triggered, and so forth.</p> </li> </ul> <p>Each flag is associated with a binary code: the first flag is given $2^{0}$, the second $2^{1}$, the third $2^{2}$, etc. A second extension, <em>QF_BINCODE</em>, is a 2D map indicating the sum of the codes for which flags were triggered for each spaxel. A value of 13 is $1 + 4 + 8 = 2^0 + 2^2 + 2^3$, meaning the first, third, and fourth flags were triggered. The flags that we use, their binary codes, and their respective criteria are listed below. The precise limits associated with many criteria were determined by visual examination to mimic what an average astronomer would suspect as `bad'.</p> <table> <thead> <tr> <th align=""left"">Flag</th> <th>Flag Name</th> <th>Flag Binary Code</th> <th>Flagged If</th> </tr> </thead> <tbody> <tr class=""even""> <td align=""left"">1</td> <td>Bad Sky Subtraction</td> <td>$2^0 = 1$</td> <td>Lines fall into risky region (redshift $&gt; 0.0103$) AND Fraction of pixels in sky (above 7235\AA) above or below 3 robust $\sigma$ is $&gt;5$%</td> </tr> <tr class=""odd""> <td align=""left"">2</td> <td>Bad Continuum Fit</td> <td>$2^1 = 2$</td> <td>Reduced $\chi^{2}$ of continuum fit $&gt;1.3$</td> </tr> <tr class=""even""> <td align=""left"">3</td> <td>Low Balmer Decrement</td> <td>$2^2 = 4$</td> <td>Balmer decrement + $\delta_{BD}$ $&lt;2.86$</td> </tr> <tr class=""odd""> <td align=""left"">4</td> <td>High Balmer Decrement</td> <td>$2^3 = 8$</td> <td>Balmer decrement - $\delta_{BD}$ $&gt;5$</td> </tr> <tr class=""even""> <td align=""left"">5</td> <td>BPT Line Ratios</td> <td>$2^4 = 16$</td> <td>Line ratios fall well outside standard physical ratios: $\log([O III] / H\beta)&gt;1.0$ OR $&lt;-1.2$ OR $\log([N II] / H\alpha) &gt;0.5$ OR $&lt;-1.5$ OR $\log([S II] / H\alpha) &gt;0.3$ OR $&lt;-1.3$</td> </tr> <tr class=""odd""> <td align=""left"">6</td> <td>Unknown # of Components</td> <td>$2^5 = 32$</td> <td>One or more multi-component fits fail, so 1-component fit is de facto rather than chosen. (Used in recom_comp cubes only).</td> </tr> <tr class=""even""> <td align=""left"">7</td> <td>No data</td> <td>$2^6=64$</td> <td>Spectrum is NaN or fits catastrophically fail.</td> </tr> </tbody> </table> <p><strong>IMPORTANT</strong>: We have erred on the side of flagging more possible errors rather than less, even though some flags may not be important for all science cases. Therefore we strongly recommend that the user examines each quality flag to decide which are important for your science case before eliminating spectra from your sample. It will be tempting to just keep spaxels with no quality flags triggered, but for most science cases, you will still be throwing out useful data. For example, residual sky lines are much more likely to affect lines on the red side, and in particular the [S II] doublet, so if you do not care about those line fluxes, you might ignore the bad sky subtraction flag. A strange Balmer decrement probably indicates an issue with the continuum fitting and therefore the Balmer line flux corrections, but if you are measuring kinematics, your science might be less affected by this issue.</p> <h1 id=""Data_Products"">Data Products</h1> <h2 id=""Kinematics_maps"">Kinematics maps</h2> <p>Line-of-sight velocity and velocity dispersion maps (and relative errors maps) obtained by fitting simultaneously 11 emission lines with a single Gaussian component. The velocities are calculated with respect to the heliocentric redshift as measured by the GAMA survey.</p> <h2 id=""Line_flux_maps"">Line flux maps</h2> <p>2D image obtained by summing all the flux associated to a given emission line in each spaxel (and relative error maps).</p> <h2 id=""Equivalent_widths_maps"">Equivalent widths maps</h2> <p>Several extensions have been added reporting the equivalent widths of Balmer lines. The extensions called HA(B)_CONT_EW contain the equivalent widths of the H$\alpha$ and H$\beta$ absorption in the fitted continuum spectra. These are measured using the intermediate windows from <a href=""http://adsabs.harvard.edu/abs/2005MNRAS.357..945G"">Gonzalez Delgado et al. 2005</a>, also described in the table below. In each case, a linear fit is performed to the fitted continuum spectrum in two windows, spanning the absorption feature. This linear fit is then divided out to normalize the spectrum before calculating the equivalent width. Absorption is indicated by a positive value.</p> <p>The extensions called HA(B)_LINE_EW contain the equivalent widths of the H$\alpha$ and H$\beta$ emission lines, which are negative to indicate emission. These equivalent widths were calculated by dividing the emission line flux (total for all components) by the median continuum level around each line (calculated in the continuum windows listed below) in order to convert its units to Angstrom.</p> <table> <thead> <tr> <th align=""left"">Line</th> <th>Line Window</th> <th>Blue Continuum Window</th> <th>Red Continuum Window</th> </tr> </thead> <tbody> <tr class=""even""> <td align=""left"">H$\alpha$</td> <td>6548-6578 A</td> <td>6506-6514 A</td> <td>6612-6620 A</td> </tr> <tr class=""odd""> <td align=""left"">H$\beta$</td> <td>4847-4877 A</td> <td>4770-4782 A</td> <td>4942-4954 A</td> </tr> </tbody> </table> <h2 id=""Extinction_Maps"">Extinction Maps</h2> <p>Extinction maps are calculated using the Balmer decrement and the <a href=""http://adsabs.harvard.edu/abs/1989ApJ...345..245C"">Cardelli et al. 1989</a> extinction law. For each spaxel:</p> <p>$balmerdec = \frac{H\alpha}{H\beta}$</p> <p>$balmerdecerr = balmerdec * [(H\alpha_{err}/H\alpha)^2 + (H\beta_{err}/H\beta)^2]^{0.5}$</p> <p>$attencorr = (\frac{balmerdec}{2.86})^{2.36}$</p> <p>$attencorrerr = |\frac{attencorr * 2.36 * balmerdecerr}{balmerdec}|$</p> <p>These maps will be in units of <em>attenuation correction factor</em> &mdash; such that you can multiply this map by the Halpha cube to obtain de-extincted Halpha cubes. Note that, when the Balmer decrement is less than 2.86, no correction will be applied (attenuation correction factor = 1., error = 0.).</p> <p>Additionally, we have set to NaN the correction and error for spaxels with Halpha flux &gt; 40 ($\times 10^{-16} erg~s~cm^{2}$) and Balmer decrement &gt; 10. These numbers were chosen to eliminate spurious Halpha fits to the edges of the fibre bundles. Errors (1-sigma uncertainties) in the extinction are included as a second extension in each file.</p> <h2 id=""Star_Formation_Rate_Masks"">Star Formation Rate Masks</h2> <p>We classify each spaxel using (when possible) [OIII]/Hbeta, [NII]/Halpha, [SII]/Halpha, and [OI]/Halpha flux ratios to determine whether the emission lines are dominated by photoionization from HII regions or other sources like AGN or shocks, using the BPT/VO87 diagnostic diagrams and dividing lines from (Kewley et al. 2006)[http://adsabs.harvard.edu/abs/2006MNRAS.372..961K]. We only classify spaxels with ratios that have a signal-to-noise ratio of at least 5. Emission is classified as star-forming in a given diagnostic if:</p> <p>$\log([OIII]/H\beta) &lt; (0.61 / (\log([NII]/H\alpha)-0.05) + 1.3$ <a href=""http://adsabs.harvard.edu/abs/2003MNRAS.346.1055K"">Kauffmann et al. 2003</a></p> <p>$\log([OIII]/H\beta) &lt; (0.72 / (\log([SII]/H\alpha)-0.32) + 1.3$ <a href=""http://adsabs.harvard.edu/abs/2001ApJ...556..121K"">Kewley et al. 2001</a></p> <p>$\log([OIII]/H\beta) &lt; (0.73 / (\log([OI]/H\alpha) +0.59) + 1.33$ <a href=""http://adsabs.harvard.edu/abs/2001ApJ...556..121K"">Kewley et al. 2001</a></p> <p>We additionally add a likely classification of ""star-forming"" to spaxels with $\log([NII]/H\alpha) &lt;-0.4$ without an [OIII] detection and to spaxels with Halpha detections but no [N II], [S II], [O I], or [O III] detections.</p> <p>Each spaxel in the map is 1 (when star formation dominates the emission in all available line ratios) or 0 (when other ionization mechanisms dominate), so it may be simply multiplied by the Halpha flux map to produce ""Halpha from star formation"" maps.</p> <h2 id=""Star_Formation_Rate_Maps"">Star Formation Rate Maps</h2> <p>Star formation rate (SFR) maps (in $M_{sun}~yr^{-1}~spaxel^{-1}$) obtained from extinction corrected H$\alpha$ maps. As distance, we are using the flow-corrected redshifts z_tonry from the SAMI-matched GAMA catalog for the GAMA regions and the cluster redshift from Owers et al. in prep. for cluster galaxies.</p> <p>$H_{0} = 70.$ [km/s/Mpc] SAMI official cosmology</p> <p>$D_{lum}=LuminosityDistance(z,H_{0}=H_{0},0.3,0.7)$ [Mpc]</p> <p>$D_{cm} = D_{lum} \times 3.086\times10^{24}$ [cm]</p> <p>$L(H\alpha) = H\alpha_{flux} \times SFR_{mask} \times attencorr \times 10^{-16} \times 4\pi \times D_{cm}^2$ [erg/s]</p> <p>$SFR = L(H\alpha) \times 7.9\times 10^{-42}$ [$\rm M_{sun}~yr^{-1}$] following <a href=""http://adsabs.harvard.edu/abs/1998ARA%26A..36..189K"">Kennicutt 1998</a></p> <p>Errors (1-sigma uncertainty) in SFR are included as a second extension in each file.</p> <hr /> <p><sup id=""fn1"">1. [at 5577, 6360, and $7340~\rm A$]<a title=""Jump back to footnote 1 in the text."" href=""#ref1"">↩</a></sup></p> <p><sup id=""fn2"">2. [[OII]3726,29, H$\delta$, H$\gamma$, [OIII]4363, H$\beta$, [OIII]4959, 5007, [OI]6300, [NII]6548,83, H$\alpha$, and [SII]6716,31]<a title=""Jump back to footnote 2 in the text."" href=""#ref2"">↩</a></sup></p>";"2016-11-24 10:22:04.865687+08";"2016-11-24 11:16:06.794527+08";;FALSE;4
37;"What is a Branch?";4;"data-central-what-is-a-branch";"<p>Branches represent different analysis pipelines for a particular data type. For example, a galaxy may have a stellar mass value calculated using method X, and a value calculated using method Y. These values&nbsp;are associated with&nbsp;the galaxy's stellar mass property, and are contained within separate branches. Switching to a different branch allows you to view the property's value as derived by that branch's analysis method.&nbsp;</p> <p>If a property has multiple branches, it will be marked by a <span class=""fa fa-code-fork"">&nbsp;</span>symbol in a dropdown in the top-right corner of the page.</p>";"2016-09-01 09:35:53.065269+08";"2016-11-24 11:17:13.53215+08";;FALSE;2
38;"What is a Version?";4;"data-central-what-is-a-version";"<p><span>Although a set of astronomical objects and their associated data products and derived properties (known as traits) are time-stamped as a Data Releases, ADC provides finer-tuned access to versioning at the Branch&nbsp;level,&nbsp;allowing team members to update a sub-set of data products/properties without issuing a full&nbsp;data release. </span></p> <p><span></span><span>Capturing changes&nbsp;at the Branch&nbsp;level allows users access to specific versions of a trait with detailed information on the change (e.g., a bug-fix to the&nbsp;analysis pipeline).&nbsp;</span></p> <p><span>You can switch versions in the Single Object Viewer and the Schema Browser using the dropdowns in the top-right corner (if a property has multiple versions, it will be marked by a <span class=""fa fa-map-pin"">&nbsp;</span>symbol). </span></p> <p>All versions for a Branch&nbsp;are shown in the Schema Browser for that Trait - under the <strong>Available Branches and Versions</strong> heading.&nbsp;</p>";"2016-09-01 09:44:45.543568+08";"2016-11-24 11:17:17.365696+08";;FALSE;3
